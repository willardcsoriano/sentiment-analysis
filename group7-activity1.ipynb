{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60640740",
   "metadata": {},
   "source": [
    "# Activity 1: Emoji-Based Sentiment Analysis\n",
    "### Group 7: Claire and Willard\n",
    "\n",
    "This notebook addresses the requirements for Activity 1, an emoji-based sentiment analysis project. It is divided into two main parts: Question A, which focuses on training a machine learning model, and Question B, which involves building a real-time sentiment analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52157c3",
   "metadata": {},
   "source": [
    "## Question A: Sentiment Analysis using a Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99129bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8642c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Dataset Head:\n",
      "   Unnamed: 0  sentiment                                               post\n",
      "0           0          1                             Good morning every one\n",
      "1           1          0  TW: S AssaultActually horrified how many frien...\n",
      "2           2          1  Thanks by has notice of me Greetings : Jossett...\n",
      "3           3          0                      its ending soon aah unhappy üòß\n",
      "4           4          1                               My real time happy üòä\n",
      "\n",
      "Emoticons Dataset Head:\n",
      "   Unnamed: 0 Emoji Unicode codepoint                         Unicode name\n",
      "0           0     üòç           0x1f60d  SMILING FACE WITH HEART-SHAPED EYES\n",
      "1           1     üò≠           0x1f62d                   LOUDLY CRYING FACE\n",
      "2           2     üòò           0x1f618                 FACE THROWING A KISS\n",
      "3           3     üòä           0x1f60a       SMILING FACE WITH SMILING EYES\n",
      "4           4     üòÅ           0x1f601      GRINNING FACE WITH SMILING EYES\n"
     ]
    }
   ],
   "source": [
    "# Load the main dataset for Question A\n",
    "file_path_q_a = \"1k_data_emoji_tweets_senti_posneg.csv\"\n",
    "df_main = pd.read_csv(file_path_q_a)\n",
    "\n",
    "# Load the reference dataset for feature engineering\n",
    "file_path_emoticons = \"15_emoticon_data.csv\"\n",
    "df_emoticons = pd.read_csv(file_path_emoticons)\n",
    "\n",
    "# Display the first 5 rows of each DataFrame to verify they loaded correctly\n",
    "print(\"Main Dataset Head:\")\n",
    "print(df_main.head())\n",
    "print(\"\\nEmoticons Dataset Head:\")\n",
    "print(df_emoticons.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee575575",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a817a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1000 non-null   int64 \n",
      " 1   sentiment   1000 non-null   int64 \n",
      " 2   post        1000 non-null   object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 23.6+ KB\n",
      "\n",
      "Descriptive Statistics:\n",
      "         Unnamed: 0   sentiment    post\n",
      "count   1000.000000  1000.00000    1000\n",
      "unique          NaN         NaN     999\n",
      "top             NaN         NaN  #NAME?\n",
      "freq            NaN         NaN       2\n",
      "mean     499.500000     0.50000     NaN\n",
      "std      288.819436     0.50025     NaN\n",
      "min        0.000000     0.00000     NaN\n",
      "25%      249.750000     0.00000     NaN\n",
      "50%      499.500000     0.50000     NaN\n",
      "75%      749.250000     1.00000     NaN\n",
      "max      999.000000     1.00000     NaN\n",
      "\n",
      "Missing Values:\n",
      "Unnamed: 0    0\n",
      "sentiment     0\n",
      "post          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get a concise summary of the DataFrame\n",
    "df_main.info()\n",
    "\n",
    "# Display descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df_main.describe(include='all'))\n",
    "\n",
    "# Check for any missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_main.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6ef67",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d2e4836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After Cleaning ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 998 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  998 non-null    int64 \n",
      " 1   post       998 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 23.4+ KB\n",
      "\n",
      "Missing Values:\n",
      "sentiment    0\n",
      "post         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willard\\AppData\\Local\\Temp\\ipykernel_8592\\92509041.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_main['post'].replace('#NAME?', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop the redundant 'Unnamed: 0' column\n",
    "df_main = df_main.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Clean the 'post' column by replacing '#NAME?' with a null value and then dropping the row\n",
    "df_main['post'].replace('#NAME?', np.nan, inplace=True)\n",
    "df_main.dropna(subset=['post'], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"--- After Cleaning ---\")\n",
    "df_main.info()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_main.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51217d91",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23e34bbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data (if not already downloaded)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "negation_words = {\"no\", \"not\", \"don't\", \"don't\"}\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def handle_negation(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    negation_found = False\n",
    "    processed_tokens = []\n",
    "    \n",
    "    for word in tokens:\n",
    "        # Check if the word is a punctuation mark to stop negation\n",
    "        if word in ['.', ',', '!', '?']:\n",
    "            negation_found = False\n",
    "            processed_tokens.append(word)\n",
    "        elif word in negation_words:\n",
    "            negation_found = True\n",
    "            processed_tokens.append(word)\n",
    "        elif negation_found and word not in stop_words:\n",
    "            processed_tokens.append(f\"{word}_NEG\")\n",
    "        else:\n",
    "            processed_tokens.append(word)\n",
    "            \n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Your original function to replace emojis\n",
    "def replace_emojis(text):\n",
    "    # Create a list of all emojis from the emoticons DataFrame\n",
    "    emojis = df_emoticons['Emoji'].tolist()\n",
    "    # Create a regular expression pattern to find any of the emojis\n",
    "    emoji_pattern = re.compile('|'.join(re.escape(e) for e in emojis))\n",
    "    return emoji_pattern.sub('_EMOJI_', str(text))\n",
    "\n",
    "# Combine both functions in your preprocessing\n",
    "df_main['post_cleaned'] = df_main['post'].apply(replace_emojis)\n",
    "df_main['post_cleaned'] = df_main['post_cleaned'].apply(handle_negation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e5b92",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93552521",
   "metadata": {},
   "source": [
    "#### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af310486",
   "metadata": {},
   "source": [
    "##### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39628d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df_main['post_cleaned']\n",
    "y = df_main['sentiment']\n",
    "\n",
    "# Split the data into 70% training and 30% for validation + testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the remaining 30% into 15% validation and 15% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32219e",
   "metadata": {},
   "source": [
    "##### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using TF-IDF. The vectorizer is fit only on the training data.\n",
    "# Add n-grams (sequences of words).\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18cf61e",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae7855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Validation Accuracy: 0.7800\n",
      "Logistic Regression Validation Accuracy: 0.7400\n",
      "Support Vector Machine (SVC) Validation Accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "# Import additional models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# --- Model 1: Multinomial Naive Bayes ---\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "nb_val_pred = nb_model.predict(X_val_vectorized)\n",
    "nb_accuracy = accuracy_score(y_val, nb_val_pred)\n",
    "print(f\"Multinomial Naive Bayes Validation Accuracy: {nb_accuracy:.4f}\")\n",
    "\n",
    "# --- Model 2: Logistic Regression ---\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_vectorized, y_train)\n",
    "lr_val_pred = lr_model.predict(X_val_vectorized)\n",
    "lr_accuracy = accuracy_score(y_val, lr_val_pred)\n",
    "print(f\"Logistic Regression Validation Accuracy: {lr_accuracy:.4f}\")\n",
    "\n",
    "# --- Model 3: Support Vector Machine (SVC) ---\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_vectorized, y_train)\n",
    "svc_val_pred = svc_model.predict(X_val_vectorized)\n",
    "svc_accuracy = accuracy_score(y_val, svc_val_pred)\n",
    "print(f\"Support Vector Machine (SVC) Validation Accuracy: {svc_accuracy:.4f}\")\n",
    "\n",
    "# Now, based on these results, select the best-performing model to evaluate on the final test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc05a3d",
   "metadata": {},
   "source": [
    "#### Chosen Model/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586137cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Test Set Accuracy: 0.8133333333333334\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82        74\n",
      "           1       0.83      0.79      0.81        76\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.81      0.81      0.81       150\n",
      "weighted avg       0.81      0.81      0.81       150\n",
      "\n",
      "\n",
      "Support Vector Machine (SVC) Test Set Accuracy: 0.8066666666666666\n",
      "Support Vector Machine (SVC) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.79        74\n",
      "           1       0.78      0.86      0.82        76\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.81      0.81      0.81       150\n",
      "weighted avg       0.81      0.81      0.81       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate Multinomial Naive Bayes on the Test Set ---\n",
    "nb_test_pred = nb_model.predict(X_test_vectorized)\n",
    "print(\"Multinomial Naive Bayes Test Set Accuracy:\", accuracy_score(y_test, nb_test_pred))\n",
    "print(\"Multinomial Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, nb_test_pred))\n",
    "\n",
    "# --- Evaluate Support Vector Machine (SVC) on the Test Set ---\n",
    "svc_test_pred = svc_model.predict(X_test_vectorized)\n",
    "print(\"\\nSupport Vector Machine (SVC) Test Set Accuracy:\", accuracy_score(y_test, svc_test_pred))\n",
    "print(\"Support Vector Machine (SVC) Classification Report:\")\n",
    "print(classification_report(y_test, svc_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c1c36",
   "metadata": {},
   "source": [
    "## Question B: Real-Time Tweet Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1b2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c30cfd920949d99f92d77f9e113050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Tweet:', placeholder='Type your sentence here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c2201a9e944752a41fddccd6de3294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Say your Sentiment', style=ButtonStyle(), tooltip='Click to analyze s‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee072cbccaf44188860eb5460389b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the ipywidgets library\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define a function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    # Use the same emoji replacement logic\n",
    "    processed_text = replace_emojis(text)\n",
    "    \n",
    "    # Vectorize the new text\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Make a prediction using the best-performing model (MultinomialNB)\n",
    "    prediction = nb_model.predict(vectorized_text)[0]\n",
    "    \n",
    "    # Convert prediction to a readable sentiment label\n",
    "    sentiment = \"POSITIVE\" if prediction == 1 else \"NEGATIVE\"\n",
    "    \n",
    "    # Display the result\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        print(f\"Your input is: \\\"{text}\\\"\")\n",
    "        print(f\"Your input is of \\\"{sentiment} SENTIMENT\\\"\")\n",
    "\n",
    "# Create the interactive widgets\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your sentence here',\n",
    "    description='Tweet:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Say your Sentiment',\n",
    "    button_style='info',\n",
    "    tooltip='Click to analyze sentiment'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Link the button to the prediction function\n",
    "def on_button_clicked(b):\n",
    "    predict_sentiment(text_input.value)\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_input, button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
