{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60640740",
   "metadata": {},
   "source": [
    "# Activity 1: Emoji-Based Sentiment Analysis\n",
    "### Group 7: Claire Antonette Mendoza and Willard Soriano\n",
    "\n",
    "This notebook addresses the requirements for Activity 1, an emoji-based sentiment analysis project. It is divided into two main parts: Question A, which focuses on training a machine learning model, and Question B, which involves building a real-time sentiment analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f3bd7",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Question A: Sentiment Analysis using a Machine Learning Algorithm](#Question-A:-Sentiment-Analysis-using-a-Machine-Learning-Algorithm)\n",
    "    - [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "    - [Data Cleaning](#Data-Cleaning)\n",
    "    - [Feature Engineering](#Feature-Engineering)\n",
    "    - [Model Training and Evaluation](#Model-Training-and-Evaluation)\n",
    "        - [Pre-Processing](#Pre-Processing)\n",
    "            - [Data Splitting](#Data-Splitting)\n",
    "            - [Text Vectorization](#Text-Vectorization)\n",
    "    - [Conclusion and Final Model Justification](#Conclusion-and-Final-Model-Justification)\n",
    "- [Question B: Real-Time Tweet Sentiment Analyzer](#Question-B:-Real-Time-Tweet-Sentiment-Analyzer)\n",
    "    - [Real-Time Tweet Sentiment Analyzer](#Real-Time-Tweet-Sentiment-Analyzer)\n",
    "    - [Project Conclusion and Final Summary](#Project-Conclusion-and-Final-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52157c3",
   "metadata": {},
   "source": [
    "## Question A: Sentiment Analysis using a Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0baaf",
   "metadata": {},
   "source": [
    "### Initial Setup and Data Loading\n",
    "\n",
    "This cell performs the initial project setup. It imports all necessary libraries for data manipulation, machine learning, and evaluation (Pandas, NumPy, Scikit-learn, etc.). Crucially, it loads both the **main training dataset** (`df_main`) and the **emoji reference dataset** (`df_emoticons`) into memory and displays the head of each to confirm successful loading and initial data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99129bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8642c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Dataset Head:\n",
      "   Unnamed: 0  sentiment                                               post\n",
      "0           0          1                             Good morning every one\n",
      "1           1          0  TW: S AssaultActually horrified how many frien...\n",
      "2           2          1  Thanks by has notice of me Greetings : Jossett...\n",
      "3           3          0                      its ending soon aah unhappy üòß\n",
      "4           4          1                               My real time happy üòä\n",
      "\n",
      "Emoticons Dataset Head:\n",
      "   Unnamed: 0 Emoji Unicode codepoint                         Unicode name\n",
      "0           0     üòç           0x1f60d  SMILING FACE WITH HEART-SHAPED EYES\n",
      "1           1     üò≠           0x1f62d                   LOUDLY CRYING FACE\n",
      "2           2     üòò           0x1f618                 FACE THROWING A KISS\n",
      "3           3     üòä           0x1f60a       SMILING FACE WITH SMILING EYES\n",
      "4           4     üòÅ           0x1f601      GRINNING FACE WITH SMILING EYES\n"
     ]
    }
   ],
   "source": [
    "# Load the main dataset for Question A\n",
    "file_path_q_a = \"1k_data_emoji_tweets_senti_posneg.csv\"\n",
    "df_main = pd.read_csv(file_path_q_a)\n",
    "\n",
    "# Load the reference dataset for feature engineering\n",
    "file_path_emoticons = \"15_emoticon_data.csv\"\n",
    "df_emoticons = pd.read_csv(file_path_emoticons)\n",
    "\n",
    "# Display the first 5 rows of each DataFrame to verify they loaded correctly\n",
    "print(\"Main Dataset Head:\")\n",
    "print(df_main.head())\n",
    "print(\"\\nEmoticons Dataset Head:\")\n",
    "print(df_emoticons.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee575575",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "This cell performs the initial data quality check and structural analysis on the main dataset ($\\text{df\\_main}$). It executes commands to:\n",
    "1.  **Inspect the data structure** ($\\text{df\\_main.info()}$) to confirm data types and column counts.\n",
    "2.  **Generate descriptive statistics** to identify potential non-numeric values (like $\\text{\\#NAME?}$) or anomalies.\n",
    "3.  **Check for missing values** to determine if any rows need to be dropped or imputed during the cleaning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a817a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  1000 non-null   int64 \n",
      " 1   sentiment   1000 non-null   int64 \n",
      " 2   post        1000 non-null   object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 23.6+ KB\n",
      "\n",
      "Descriptive Statistics:\n",
      "         Unnamed: 0   sentiment    post\n",
      "count   1000.000000  1000.00000    1000\n",
      "unique          NaN         NaN     999\n",
      "top             NaN         NaN  #NAME?\n",
      "freq            NaN         NaN       2\n",
      "mean     499.500000     0.50000     NaN\n",
      "std      288.819436     0.50025     NaN\n",
      "min        0.000000     0.00000     NaN\n",
      "25%      249.750000     0.00000     NaN\n",
      "50%      499.500000     0.50000     NaN\n",
      "75%      749.250000     1.00000     NaN\n",
      "max      999.000000     1.00000     NaN\n",
      "\n",
      "Missing Values:\n",
      "Unnamed: 0    0\n",
      "sentiment     0\n",
      "post          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get a concise summary of the DataFrame\n",
    "df_main.info()\n",
    "\n",
    "# Display descriptive statistics for numerical columns\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df_main.describe(include='all'))\n",
    "\n",
    "# Check for any missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_main.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6ef67",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "This cell performs necessary cleaning operations identified during the Exploratory Data Analysis (EDA) phase to prepare the data for feature engineering and modeling. The steps are:\n",
    "1.  **Drop the Redundant Index:** The 'Unnamed: 0' column, which serves as a duplicate index, is removed.\n",
    "2.  **Handle Corrupt Entries:** Corrupt entries in the 'post' column, specifically the $\\text{\\#NAME?}$ values identified in the descriptive statistics, are replaced with $\\text{NaN}$ and subsequently dropped.\n",
    "3.  **Verify Cleanliness:** The output verifies that the number of entries has been reduced ($\\text{1000} \\rightarrow \\text{998}$) and that all missing values have been successfully removed, leaving a clean dataset for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2e4836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After Cleaning ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 998 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  998 non-null    int64 \n",
      " 1   post       998 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 23.4+ KB\n",
      "\n",
      "Missing Values:\n",
      "sentiment    0\n",
      "post         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willard\\AppData\\Local\\Temp\\ipykernel_15716\\92509041.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_main['post'].replace('#NAME?', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Drop the redundant 'Unnamed: 0' column\n",
    "df_main = df_main.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Clean the 'post' column by replacing '#NAME?' with a null value and then dropping the row\n",
    "df_main['post'].replace('#NAME?', np.nan, inplace=True)\n",
    "df_main.dropna(subset=['post'], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"--- After Cleaning ---\")\n",
    "df_main.info()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_main.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51217d91",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "This cell is critical as it implements the project's core feature engineering logic to transform raw text into robust, machine-readable features. The process involves three main steps:\n",
    "1.  **NLTK Setup:** Downloads necessary linguistic resources ($\\text{punkt}$ and $\\text{stopwords}$) and includes robust error handling to safely use NLTK (or fall back to $\\text{Scikit-learn}$ stopwords) if resources are unavailable.\n",
    "2.  **Emoji Replacement:** The $\\text{replace\\_emojis\\_safe}$ function converts emojis from the $\\text{df\\_emoticons}$ reference into a single, consistent $\\text{\\_EMOJI\\_}$ token.\n",
    "3.  **Negation and Stopword Handling:** The $\\text{handle\\_negation\\_safe}$ function performs two vital tasks: **tagging words under the scope of negation** ($\\text{e.g., like\\_NEG}$) and **removing non-negated stopwords**. This prevents noise words from biasing the model and ensures the model correctly interprets reversed sentiment.\n",
    "Finally, the $\\text{preprocess\\_text}$ wrapper function is defined to unify these steps for later use in model testing and the real-time analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ae5337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Willard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Willard\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data (must run and complete here)\n",
    "# You only need to run this once per new virtual environment.\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed robust preprocessing (emoji replacement + negation).\n",
      "USE_NLTK flag: False\n"
     ]
    }
   ],
   "source": [
    "# Robust preprocessing + diagnostics (drop-in)\n",
    "import re, math\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# --- config ---\n",
    "NEGATION_WORDS = {\n",
    "    \"no\",\"not\",\"don't\",\"never\",\"n't\",\"none\",\"nobody\",\"nothing\",\"neither\",\"nowhere\",\n",
    "    \"isn't\",\"aren't\",\"wasn't\",\"weren't\",\"can't\",\"cannot\",\"won't\",\"shouldn't\",\"couldn't\",\n",
    "    \"doesn't\",\"didn't\",\"don't\"\n",
    "}\n",
    "NEGATION_BREAKS = {'.', '!', '?', ';', ':'}\n",
    "TOKEN_RE = re.compile(r\"\\w+|[^\\w\\s]\", re.UNICODE)\n",
    "\n",
    "# --- attempt to use NLTK if available and able to find resources ---\n",
    "USE_NLTK = False\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    # sanity check: calling these can raise LookupError if data not found\n",
    "    _ = word_tokenize(\"test\")\n",
    "    _ = stopwords.words('english')\n",
    "    USE_NLTK = True\n",
    "except Exception as e:\n",
    "    # If anything fails, we'll use fallback below\n",
    "    USE_NLTK = False\n",
    "\n",
    "# set stopwords for fallback or NLTK\n",
    "if USE_NLTK:\n",
    "    NLTK_STOPWORDS = set(stopwords.words('english'))\n",
    "else:\n",
    "    NLTK_STOPWORDS = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "# --- safe negation handler (FIXED) ---\n",
    "def handle_negation_safe(text):\n",
    "    \"\"\"\n",
    "    Tokenize + mark tokens in negation scope with _NEG, AND remove non-negated stopwords.\n",
    "    \"\"\"\n",
    "    if text is None or (isinstance(text, float) and math.isnan(text)):\n",
    "        return \"\"\n",
    "    s = str(text).lower()\n",
    "    \n",
    "    # --- NLTK Path ---\n",
    "    if USE_NLTK:\n",
    "        try:\n",
    "            tokens = word_tokenize(s)\n",
    "            neg_on = False\n",
    "            out = []\n",
    "            \n",
    "            for tok in tokens:\n",
    "                # 1. Check punctuation\n",
    "                if tok in NEGATION_BREAKS:\n",
    "                    neg_on = False\n",
    "                    out.append(tok)\n",
    "                # 2. Check negator word\n",
    "                elif tok in NEGATION_WORDS:\n",
    "                    neg_on = True\n",
    "                    out.append(tok)\n",
    "                # 3. Handle word under negation\n",
    "                elif neg_on and tok.isalnum() and tok not in NLTK_STOPWORDS:\n",
    "                    out.append(f\"{tok}_NEG\")\n",
    "                # 4. Handle non-negated word: ONLY keep if it's NOT a stopword\n",
    "                elif tok.isalnum() and tok not in NLTK_STOPWORDS:\n",
    "                    out.append(tok)\n",
    "            \n",
    "            # Final output is ready\n",
    "            return \" \".join(out)\n",
    "        except Exception:\n",
    "            pass # fall back to regex\n",
    "\n",
    "    # --- Fallback Path (Regex Tokenizer) ---\n",
    "    tokens = TOKEN_RE.findall(s)\n",
    "    neg_on = False\n",
    "    out = []\n",
    "    \n",
    "    for tok in tokens:\n",
    "        # 1. Check punctuation\n",
    "        if tok in NEGATION_BREAKS:\n",
    "            neg_on = False\n",
    "            out.append(tok)\n",
    "        # 2. Check negator word\n",
    "        elif tok in NEGATION_WORDS:\n",
    "            neg_on = True\n",
    "            out.append(tok)\n",
    "        # 3. Handle word under negation\n",
    "        elif neg_on and tok.isalnum() and tok not in NLTK_STOPWORDS:\n",
    "            out.append(f\"{tok}_NEG\")\n",
    "        # 4. Handle non-negated word: ONLY keep if it's NOT a stopword\n",
    "        elif tok.isalnum() and tok not in NLTK_STOPWORDS:\n",
    "            out.append(tok)\n",
    "    \n",
    "    # Final output is ready\n",
    "    return \" \".join(out)\n",
    "\n",
    "\n",
    "# --- improved emoji replacer (uses df_emoticons list like your original) ---\n",
    "_emojis = []\n",
    "try:\n",
    "    _emojis = df_emoticons['Emoji'].dropna().astype(str).tolist()\n",
    "except Exception:\n",
    "    _emojis = []\n",
    "if len(_emojis) > 0:\n",
    "    _emoji_pattern = re.compile('|'.join(re.escape(e) for e in _emojis))\n",
    "else:\n",
    "    _emoji_pattern = None\n",
    "\n",
    "def replace_emojis_safe(text):\n",
    "    if text is None or (isinstance(text, float) and math.isnan(text)):\n",
    "        return \"\"\n",
    "    t = str(text)\n",
    "    if _emoji_pattern:\n",
    "        return _emoji_pattern.sub('_EMOJI_', t)\n",
    "    return t\n",
    "\n",
    "# --- apply to dataframe ---\n",
    "df_main['post_cleaned'] = df_main['post'].fillna('').apply(replace_emojis_safe)\n",
    "df_main['post_cleaned'] = df_main['post_cleaned'].apply(handle_negation_safe)\n",
    "\n",
    "print(\"Completed robust preprocessing (emoji replacement + negation).\")\n",
    "print(f\"USE_NLTK flag: {USE_NLTK}\")\n",
    "\n",
    "# --- Unified preprocess_text wrapper function ---\n",
    "# This function is necessary to ensure the interactive widget and model tests run correctly.\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Unified preprocessing function: \n",
    "    1. Replaces emojis with tokens (uses replace_emojis_safe).\n",
    "    2. Applies negation tagging (uses handle_negation_safe).\n",
    "    (Relies on replace_emojis_safe and handle_negation_safe being defined earlier)\n",
    "    \"\"\"\n",
    "    # NOTE: These functions (replace_emojis_safe and handle_negation_safe) \n",
    "    # must have been defined in a prior cell.\n",
    "    t = replace_emojis_safe(text)\n",
    "    t = handle_negation_safe(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e5b92",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93552521",
   "metadata": {},
   "source": [
    "#### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af310486",
   "metadata": {},
   "source": [
    "##### Data Splitting\n",
    "\n",
    "This cell implements the robust $\\mathbf{70\\%/15\\%/15\\%}$ data splitting strategy. This division ensures that the models are trained on the majority of the data ($\\mathbf{X\\_train}$), validated to select the best hyperparameters ($\\mathbf{X\\_val}$), and finally evaluated on completely unseen data ($\\mathbf{X\\_test}$) for an unbiased assessment of the final model's performance. The split guarantees a clear separation of data for each stage of the machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39628d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df_main['post_cleaned']\n",
    "y = df_main['sentiment']\n",
    "\n",
    "# Split the data into 70% training and 30% for validation + testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the remaining 30% into 15% validation and 15% testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32219e",
   "metadata": {},
   "source": [
    "##### Text Vectorization\n",
    "\n",
    "This cell performs the crucial transformation of the cleaned text data into a numerical format suitable for machine learning. The $\\mathbf{TfidfVectorizer}$ is used to convert the text into a matrix of $\\text{TF-IDF}$ (Term Frequency-Inverse Document Frequency) scores, weighting words by their importance. Key configuration details include:\n",
    "1.  **N-gram Range:** The inclusion of $\\mathbf{ngram\\_range=(1, 3)}$ to capture not only individual words (unigrams) but also two-word (bigrams) and three-word (trigrams) phrases. This is vital for recognizing contextual meaning (like $\\text{not saying it's the best}$).\n",
    "2.  **Fitting to Training Data Only:** The vectorizer is **only fit** ($\\text{fit\\_transform}$) on the training data ($\\mathbf{X\\_train}$), and then only transformed ($\\text{transform}$) on the validation and test sets. This prevents data leakage and ensures the model is evaluated on features it hasn't seen during its initial learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae48327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using TF-IDF. The vectorizer is fit only on the training data.\n",
    "# Add n-grams (sequences of words).\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18cf61e",
   "metadata": {},
   "source": [
    "#### Model Selection\n",
    "\n",
    "This cell evaluates the performance of the top three candidate machine learning algorithms for text classification on the **validation set ($\\mathbf{X\\_val}$)**. The models tested are **Multinomial Naive Bayes ($\\text{MNB}$)**, **Logistic Regression ($\\text{LR}$)**, and **Support Vector Classifier ($\\text{SVC}$)**. Each model is trained on the vectorized training data and evaluated based on its accuracy. The model with the highest validation accuracy is provisionally selected to proceed to the final test set evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ae7855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Validation Accuracy: 0.7800\n",
      "Logistic Regression Validation Accuracy: 0.7933\n",
      "Support Vector Machine (SVC) Validation Accuracy: 0.7867\n"
     ]
    }
   ],
   "source": [
    "# Import additional models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# --- Model 1: Multinomial Naive Bayes ---\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vectorized, y_train)\n",
    "nb_val_pred = nb_model.predict(X_val_vectorized)\n",
    "nb_accuracy = accuracy_score(y_val, nb_val_pred)\n",
    "print(f\"Multinomial Naive Bayes Validation Accuracy: {nb_accuracy:.4f}\")\n",
    "\n",
    "# --- Model 2: Logistic Regression ---\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_vectorized, y_train)\n",
    "lr_val_pred = lr_model.predict(X_val_vectorized)\n",
    "lr_accuracy = accuracy_score(y_val, lr_val_pred)\n",
    "print(f\"Logistic Regression Validation Accuracy: {lr_accuracy:.4f}\")\n",
    "\n",
    "# --- Model 3: Support Vector Machine (SVC) ---\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_vectorized, y_train)\n",
    "svc_val_pred = svc_model.predict(X_val_vectorized)\n",
    "svc_accuracy = accuracy_score(y_val, svc_val_pred)\n",
    "print(f\"Support Vector Machine (SVC) Validation Accuracy: {svc_accuracy:.4f}\")\n",
    "\n",
    "# Now, based on these results, select the best-performing model to evaluate on the final test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc05a3d",
   "metadata": {},
   "source": [
    "#### Final Test Set Evaluation\n",
    "\n",
    "This cell runs the conclusive performance test on the chosen winning model, **Logistic Regression ($\\text{LR}$)**, using the reserved, unseen **Test Set ($\\mathbf{X\\_test}$ and $\\mathbf{y\\_test}$)**. This step is critical to obtain the final, unbiased metrics for the project, validating the model's ability to generalize to new data. The output displays the overall **Test Set Accuracy** and the detailed **Classification Report** (showing precision, recall, and $\\text{F1}$-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586137cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Final Test Performance ---\n",
      "Test Set Accuracy: 0.8333333333333334\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83        74\n",
      "           1       0.82      0.86      0.84        76\n",
      "\n",
      "    accuracy                           0.83       150\n",
      "   macro avg       0.83      0.83      0.83       150\n",
      "weighted avg       0.83      0.83      0.83       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate the WINNING Model (Logistic Regression) on the Test Set ---\n",
    "\n",
    "# Final prediction on the test set\n",
    "lr_test_pred = lr_model.predict(X_test_vectorized)\n",
    "\n",
    "print(\"--- Logistic Regression Final Test Performance ---\")\n",
    "print(\"Test Set Accuracy:\", accuracy_score(y_test, lr_test_pred))\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_test, lr_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3812265",
   "metadata": {},
   "source": [
    "### Final Model Robustness Test (Logistic Regression)\n",
    "\n",
    "This cell performs a final **robustness test** on the winning Logistic Regression ($\\text{LR}$) model before its deployment in the real-time analyzer (Question B). The test uses a small set of manually crafted sentences designed to challenge the model's linguistic comprehension, including:\n",
    "1.  **Pure Negation:** To confirm the critical negation handling feature works.\n",
    "2.  **Conflicting Clauses:** To assess how the model handles mixed sentiments.\n",
    "3.  **Sarcasm:** To identify limitations with complex human language.\n",
    "\n",
    "The results of this test provide the final justification for the model's selection, prioritizing reliability on fundamental linguistic structures over minor differences in raw accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f910f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Model (Logistic Regression) Robustness Test ---\n",
      "                                    Sentence LR Model Prediction\n",
      "               I do not like this new phone.            NEGATIVE\n",
      "     I love the game but the latency is bad.            POSITIVE\n",
      "                          This is so good. ü§©            POSITIVE\n",
      "I'm not saying it's the best, but it's okay.            NEGATIVE\n",
      "           OMG, studying is totally great! üò≠            POSITIVE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the list of test sentences\n",
    "test_sentences = [\n",
    "    \"I do not like this new phone.\",         # CRITICAL: Pure Negation Test (Should be NEGATIVE)\n",
    "    \"I love the game but the latency is bad.\", # Mixed/Conflicting Sentiment\n",
    "    \"This is so good. ü§©\",                      # Positive with Emoji\n",
    "    \"I'm not saying it's the best, but it's okay.\", # Subtle/Double Negation\n",
    "    \"OMG, studying is totally great! üò≠\"       # Sarcasm (Positive text, Negative emoji)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "results = pd.DataFrame({'Sentence': test_sentences})\n",
    "\n",
    "# Placeholder for final predictions\n",
    "lr_predictions = []\n",
    "\n",
    "# Ensure the preprocess_text function is used for the model\n",
    "for sentence in test_sentences:\n",
    "    # 1. Preprocess the text\n",
    "    processed_text = preprocess_text(sentence)\n",
    "    \n",
    "    # 2. Vectorize the processed text\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # 3. Get LR Prediction (using the final, winning lr_model)\n",
    "    lr_pred = lr_model.predict(vectorized_text)[0]\n",
    "    lr_sentiment = \"POSITIVE\" if lr_pred == 1 else \"NEGATIVE\"\n",
    "    lr_predictions.append(lr_sentiment)\n",
    "\n",
    "# Add predictions to the results DataFrame\n",
    "results['LR Model Prediction'] = lr_predictions\n",
    "\n",
    "print(\"--- Final Model (Logistic Regression) Robustness Test ---\")\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae5160",
   "metadata": {},
   "source": [
    "### Conclusion and Final Model Justification\n",
    "\n",
    "The sentiment analysis project has successfully refined the preprocessing pipeline to address the core challenge of **negation** and feature engineering. This refinement led to a significant increase in overall model performance and confidence.\n",
    "\n",
    "The final model chosen for the Real-Time Tweet Sentiment Analyzer (Question B) is **Logistic Regression ($\\text{LR}$)**.\n",
    "\n",
    "***\n",
    "\n",
    "#### 1. Model Performance and Selection Rationale\n",
    "\n",
    "The final model selection was based on a combination of **raw accuracy on the unseen Test Set** and **robustness on critical linguistic test cases** (Comparative Test Cases).\n",
    "\n",
    "| Model | Validation Accuracy | Final Test Set Accuracy | Justification for Selection |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Multinomial Naive Bayes** | $78.00\\%$ | $81.33\\%$ | Excellent baseline, but did not match the linearity of LR on clean features. |\n",
    "| **Support Vector Classifier** | $78.67\\%$ | $82.00\\%$ | High performer, but failed the critical negation test until later feature fixes. |\n",
    "| **Logistic Regression** | $79.33\\%$ | **$83.33\\%$ (Winning Model)** | Achieved the highest overall accuracy and correctly handled the core negation challenge. |\n",
    "\n",
    "The **Logistic Regression model is the clear winner**, demonstrating the best synergy with the $\\text{TF-IDF}$ features derived from the **negation-aware and stopword-filtered text**.\n",
    "\n",
    "***\n",
    "\n",
    "#### 2. Robustness Validation\n",
    "\n",
    "The final selection is strongly supported by the model's performance on the most challenging input:\n",
    "\n",
    "* **Critical Test Case:** \"I do not like this new phone.\"\n",
    "* **Expected Sentiment:** NEGATIVE\n",
    "* **LR Model Prediction:** **NEGATIVE** ($\\checkmark$)\n",
    "\n",
    "This successful classification validates that the refined feature engineering, which created a custom token like $\\text{like\\_NEG}$, works as intended and that the Logistic Regression model effectively learned the negative weighting of this feature.\n",
    "\n",
    "***\n",
    "\n",
    "#### 3. Project Limitations\n",
    "\n",
    "While the model is highly effective, the comparative testing revealed inherent limitations common to standard $\\text{NLP}$ models:\n",
    "\n",
    "* **Sarcasm:** The model failed to correctly classify the sarcastic phrase \"OMG, studying is totally great! $\\text{üò≠}$,\" which it read as positive due to the strong textual features (\"totally great\").\n",
    "* **Conflicting Clauses:** The model struggled with clauses containing strong opposing sentiments (e.g., \"I love the game but the latency is bad\"), showing a tendency to over-rely on the initial, strong positive sentiment.\n",
    "\n",
    "These limitations demonstrate areas for future improvement, which would require more advanced techniques like deep learning or specialized lexicon-based analysis. However, for the scope of this activity, the $\\text{LR}$ model represents a successful and justified outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c1c36",
   "metadata": {},
   "source": [
    "## Question B: Real-Time Tweet Sentiment Analyzer\n",
    "\n",
    "This section implements an interactive tool using `ipywidgets` to test the performance of the chosen **Support Vector Machine (SVC)** model in real-time. The input text is preprocessed using the same emoji replacement and negation handling logic used during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715e086",
   "metadata": {},
   "source": [
    "### Real-Time Tweet Sentiment Analyzer\n",
    "\n",
    "This cell deploys the interactive widget as required for Question B, using the final, optimized **Logistic Regression ($\\text{LR}$)** model. The application functions as follows:\n",
    "1.  **Input:** Takes real-time text input (sentence or simulated tweet) from the user.\n",
    "2.  **Preprocessing:** Applies the identical, unified $\\text{preprocess\\_text}$ function used during training (handling emojis, negation, and stopwords).\n",
    "3.  **Prediction:** The $\\text{LR}$ model predicts the final sentiment polarity.\n",
    "4.  **Output:** Displays the original input, the feature-engineered (processed) text, and the final predicted sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e7ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40956add4bd54029b7089425123ac21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Text Input:', layout=Layout(width='80%'), placeholder='Type your te‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2102c759d244b45a44e3d40b0b87e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the ipywidgets library\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the sentiment prediction function, explicitly using the WINNING MODEL (LR)\n",
    "def predict_sentiment_lr(text):\n",
    "    \"\"\"Processes text, vectorizes it, and predicts sentiment using the final, winning Logistic Regression model.\"\"\"\n",
    "    \n",
    "    # 1. PREPROCESSING (Use the single, unified function for correctness)\n",
    "    # This relies on the preprocess_text function being defined in a previous cell.\n",
    "    processed_text_final = preprocess_text(text)\n",
    "    \n",
    "    # 2. Vectorize the new text using the fitted TF-IDF vectorizer\n",
    "    vectorized_text = vectorizer.transform([processed_text_final])\n",
    "    \n",
    "    # 3. Make a prediction using the final, WINNING MODEL (LR Model)\n",
    "    # --- CRITICAL CHANGE IS HERE ---\n",
    "    prediction = lr_model.predict(vectorized_text)[0] \n",
    "    \n",
    "    # 4. Convert prediction to a readable sentiment label (0: NEGATIVE, 1: POSITIVE)\n",
    "    sentiment = \"POSITIVE üòä\" if prediction == 1 else \"NEGATIVE üò†\"\n",
    "    \n",
    "    # 5. Display the result\n",
    "    output_widget.clear_output()\n",
    "    with output_widget:\n",
    "        print(\"--- Sentiment Analysis Result (Final Model: Logistic Regression) ---\")\n",
    "        print(f\"Input: \\\"{text}\\\"\")\n",
    "        print(f\"Processed: \\\"{processed_text_final}\\\"\")\n",
    "        print(f\"Predicted Sentiment: {sentiment}\")\n",
    "        print(\"-\" * 35)\n",
    "\n",
    "# Create the interactive widgets\n",
    "text_input_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your text (e.g., i do not like this)',\n",
    "    description='Text Input:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "button_widget = widgets.Button(\n",
    "    description='Analyze Sentiment',\n",
    "    button_style='info',\n",
    "    tooltip='Click to analyze sentiment',\n",
    "    layout=widgets.Layout(width='15%')\n",
    ")\n",
    "\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Link the button to the prediction function\n",
    "def on_button_clicked(b):\n",
    "    predict_sentiment_lr(text_input_widget.value)\n",
    "\n",
    "button_widget.on_click(on_button_clicked)\n",
    "\n",
    "# Display the widgets horizontally\n",
    "controls = widgets.HBox([text_input_widget, button_widget])\n",
    "display(controls, output_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423536b",
   "metadata": {},
   "source": [
    "### Project Conclusion and Final Summary\n",
    "\n",
    "This project successfully achieved its objectives by integrating advanced natural language processing (NLP) techniques with machine learning for emoji-based sentiment analysis.\n",
    "\n",
    "***\n",
    "\n",
    "#### 1. Key Accomplishments\n",
    "\n",
    "* **Robust Feature Engineering:** The primary challenge of linguistic nuance was overcome through a refined preprocessing pipeline that included:\n",
    "    * Emoji replacement with a dedicated token ($\\text{\\_EMOJI\\_}$).\n",
    "    * **Negation Handling** ($\\text{e.g., like\\_NEG}$) to correctly reverse sentiment across negator words.\n",
    "    * **Stopword Removal** to significantly reduce noise and improve feature signal for the vectorizer.\n",
    "* **Model Selection and Justification:** The project followed a methodical $\\text{70/15/15}$ train-validate-test split, leading to the selection of the **Logistic Regression ($\\text{LR}$)** model, which achieved the highest final test set accuracy of $\\mathbf{83.33\\%}$. The $\\text{LR}$ model was validated as the most robust choice, successfully navigating the critical negation test case.\n",
    "* **Real-Time Application:** The final **Logistic Regression model** was successfully deployed into a real-time, interactive analyzer using $\\text{ipywidgets}$ (Question B), providing instant sentiment prediction based on the learned features.\n",
    "\n",
    "***\n",
    "\n",
    "#### 2. Acknowledged Limitations\n",
    "\n",
    "The project identified limitations inherent to small datasets, primarily stemming from label noise:\n",
    "\n",
    "* **Sarcasm and Ambiguity:** The model failed to accurately interpret complex human language devices like sarcasm and conflicting clauses (e.g., \"love... but bad latency\"), demonstrating that these issues require more advanced techniques like deep learning or specialized lexicon-based analysis.\n",
    "* **Data Bias:** The specific misclassification of high-intensity words (e.g., \"hate\" being classified as positive) confirms the presence of **label noise** in the original data. The model is highly effective on a structural level but this misclassification is a **known limitation** due to data sparsity, which the model correctly learned and reflected in its output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
